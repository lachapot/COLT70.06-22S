{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dff40d1-aaf4-456f-b262-f3b70f68d6e5",
   "metadata": {},
   "source": [
    "# Optical Character Recognition (OCR) using ImageMagic and Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e117be-986d-4984-8629-591f84058f97",
   "metadata": {},
   "source": [
    "Creating usable digital text is the precondition to text analysis. Much of computational text analysis relies on Optical Character Recognition — on the possibility of converting scanned images to machine-encoded text. Yet OCR quality remains an issue and fundamentally impact the possibilities of analysis. \n",
    "\n",
    "> “OCR techniques still favor a very particular type of Roman-based font, which omits non-Western print traditions like Chinese woodblocks, non-print traditions like medieval manuscripts, or even regionally eclectic print traditions like German Fraktur.” (Piper, Andrew, et al. \"The Page Image: Towards a Visual History of Digital Documents.\" Book History, vol. 23, 2020, p. 365-397., p. 366)\n",
    "\n",
    "> “OCR was largely developed to process typewritten, English-language, mid-twentieth-century business documents. With that kind of input, OCR is remarkably reliable, transcribing with accuracy in the upper 90 percents. Turn an OCR engine toward historical documents, however, with distinct typography, complex layouts, torn pages, smeared ink, and any number of features those OCR engines were not trained to discern, then the reliability of OCR transcription declines precipitously.” (Cordell, Ryan. [\"Why You (A Humanist) Should Care About Optical Character Recognition\"](https://ryancordell.org/research/why-ocr/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36ff9dd2-4928-4b45-b802-1ecabbf04954",
   "metadata": {},
   "source": [
    "### Is my PDF an image or a text?  \n",
    "\n",
    "It may be the case that your PDFs already contain a layer of text, in which case you don’t need to OCR them, just convert them directly into txt. You can check using Xpdf which will output .txt files from PDFs — if there is no text layer the outputted .txt will be blank. \n",
    "\n",
    "Note that Xpdf is not available on the JupyterHub environment. You’d have to install [Xpdf](https://www.xpdfreader.com/download.html) onto your own devices to use it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "253af3db-87b4-432d-9e4b-26eb17b4d93f",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pdftotext PATH/TO/FILENAME.pdf PATH/TO/OUTPUTFILENAME.txt\n",
    "!open PATH/TO/FILENAME.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "026e9e33-3ed3-4edf-b8fc-8667468190da",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pdftotext ocr-corpus/1998_Location.pdf ocr-corpus/1998_Location.txt\n",
    "!open ocr-corpus/1998_Location.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea48d0-1c5d-41fc-ae97-979c27058d15",
   "metadata": {},
   "source": [
    "## Image Preprocessing: Improve image quality with ImageMagic\n",
    "\n",
    "Tesseract requires high quality TIFF (Tagged Image File Format) images to work well. Some images will be easier to OCR than others. A good quality image will improve the accuracy of the OCR. Some images might have a lot of “noise” — distracting variations in brightness, differences in fonts and sizes, errant markings, speckled pages, skewed pages, damage to the document. Things you can do to improve image quality include: crop the picture to remove excess border space; straight the image (deskew); remove noise.\n",
    "\n",
    "We can do some preprocessing of the image to try and minimize noise and its impact on OCR quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80458ec3-8e0b-4bd2-a24e-54688eb028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pdf to tiff and improve image quality\n",
    "!convert -density 300 PATH/TO/INPUT_FILENAME.pdf -depth 8 -strip -background white -alpha off OUTPUT_FILENAME.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8e515f-cca6-4cbc-8ca8-87d2df847047",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pdf to tiff and improve image quality\n",
    "!convert -density 300 ocr-corpus/1998_Location.pdf -depth 8 -strip -background white -alpha off ocr-corpus/1998_Location.tiff"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5b50656-3b39-4278-ae2c-2795f6f4b4df",
   "metadata": {},
   "source": [
    "N.B. The JupyterHub environment seems to have some security patches that prevent ImageMagick from converting PDFs. You may need to install [ImageMagick](https://imagemagick.org/script/download.php) on your own devices and run these commands in the command line if it's not working."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cf1a179-02d6-449a-aeaa-eb63383652b5",
   "metadata": {},
   "source": [
    "`density *width*`\n",
    "controls image resolution\n",
    "\n",
    "`depth *value*`\n",
    "controls depth of the image\n",
    "\n",
    "`strip`\n",
    "strips the document of any comments or any extraneous information\n",
    "\n",
    "`background *colour*`\n",
    "sets the background color\n",
    "\n",
    "`alpha *type*`\n",
    "controls the transparency of  a colour–if it is off it means that the source color will not be visible\n",
    "\n",
    "The `density` and `depth` commands both make sure the file has the appropriate dots per inch (DPI) for OCR. The `strip`, `background`, and `alpha` commands make sure that the file has the right background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6d2e7-582b-4d0e-bee0-2ad737546b77",
   "metadata": {},
   "source": [
    "## OCR with Tesseract and Pytesseract\n",
    "\n",
    "Tesseract supports over 110 languages including non-western languages and writing systems. It is a free and open-source software maintained by Google. It can be a good alternative to commercial software, such as ABBYY FineReader.  \n",
    "\n",
    "Note that Tesseract is not supported in the JupyterHub environment. You’d have to install [Tesseract and its language packages](https://tesseract-ocr.github.io/tessdoc/Installation.html) on your own devices.\n",
    "\n",
    "Now that you have converted your files into TIFF and preprocessed your images you can use Tesseract to recognize and extract the text from the image. \n",
    "\n",
    "At its simplest, OCRing with tesseract follows a simple syntax:\n",
    "`tesseract imagename outputbase`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c33d40d7-90c0-4608-8d78-8945c4576904",
   "metadata": {},
   "outputs": [],
   "source": [
    "!tesseract ocr-corpus/1998_Location.tiff ocr-corpus/1998_Location -l eng txt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9588b-3797-42bc-92db-8a11b2ea3250",
   "metadata": {},
   "source": [
    "A number of options can be added:\n",
    "- `-l *LANG*`\n",
    "\n",
    "Add `-l LANG` to the command where LANG is the three character language code from the list of supported languages.  \n",
    "\n",
    "English is used as default language. \n",
    "\n",
    "Languages in Tesseract:\n",
    "afr (Afrikaans), amh (Amharic), ara (Arabic), asm (Assamese), aze (Azerbaijani), aze_cyrl (Azerbaijani - Cyrilic), bel (Belarusian), ben (Bengali), bod (Tibetan), bos (Bosnian), bre (Breton), bul (Bulgarian), cat (Catalan; Valencian), ceb (Cebuano), ces (Czech), chi_sim (Chinese simplified), chi_tra (Chinese traditional), chr (Cherokee), cos (Corsican), cym (Welsh), dan (Danish), deu (German), div (Dhivehi), dzo (Dzongkha), ell (Greek, Modern, 1453-), eng (English), enm (English, Middle, 1100-1500), epo (Esperanto), equ (Math / equation detection module), est (Estonian), eus (Basque), fas (Persian), fao (Faroese), fil (Filipino), fin (Finnish), fra (French), frk (Frankish), frm (French, Middle, ca.1400-1600), fry (West Frisian), gla (Scottish Gaelic), gle (Irish), glg (Galician), grc (Greek, Ancient, to 1453), guj (Gujarati), hat (Haitian; Haitian Creole), heb (Hebrew), hin (Hindi), hrv (Croatian), hun (Hungarian), hye (Armenian), iku (Inuktitut), ind (Indonesian), isl (Icelandic), ita (Italian), ita_old (Italian - Old), jav (Javanese), jpn (Japanese), kan (Kannada), kat (Georgian), kat_old (Georgian - Old), kaz (Kazakh), khm (Central Khmer), kir (Kirghiz; Kyrgyz), kmr (Kurdish Kurmanji), kor (Korean), kor_vert (Korean vertical), lao (Lao), lat (Latin), lav (Latvian), lit (Lithuanian), ltz (Luxembourgish), mal (Malayalam), mar (Marathi), mkd (Macedonian), mlt (Maltese), mon (Mongolian), mri (Maori), msa (Malay), mya (Burmese), nep (Nepali), nld (Dutch; Flemish), nor (Norwegian), oci (Occitan post 1500), ori (Oriya), osd (Orientation and script detection module), pan (Panjabi; Punjabi), pol (Polish), por (Portuguese), pus (Pushto; Pashto), que (Quechua), ron (Romanian; Moldavian; Moldovan), rus (Russian), san (Sanskrit), sin (Sinhala; Sinhalese), slk (Slovak), slv (Slovenian), snd (Sindhi), spa (Spanish; Castilian), spa_old (Spanish; Castilian - Old), sqi (Albanian), srp (Serbian), srp_latn (Serbian - Latin), sun (Sundanese), swa (Swahili), swe (Swedish), syr (Syriac), tam (Tamil), tat (Tatar), tel (Telugu), tgk (Tajik), tha (Thai), tir (Tigrinya), ton (Tonga), tur (Turkish), uig (Uighur; Uyghur), ukr (Ukrainian), urd (Urdu), uzb (Uzbek), uzb_cyrl (Uzbek - Cyrilic), vie (Vietnamese), yid (Yiddish), yor (Yoruba)\n",
    "\n",
    "If the language you are using is not included but you have trained model for this language already you can pipe in the model to Tesseract and use your own model for OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9314152-8923-4fd2-bc93-9791ffd16480",
   "metadata": {},
   "source": [
    "- `-l *SCRIPT*`  \n",
    "\n",
    "Specifies the script to use. \n",
    "\n",
    "Scripts in Tesseract: Arabic, Armenian, Bengali, Canadian_Aboriginal, Cherokee, Cyrillic, Devanagari, Ethiopic, Fraktur, Georgian, Greek, Gujarati, Gurmukhi, HanS (Han simplified), HanS_vert (Han simplified, vertical), HanT (Han traditional), HanT_vert (Han traditional, vertical), Hangul, Hangul_vert (Hangul vertical), Hebrew, Japanese, Japanese_vert (Japanese vertical), Kannada, Khmer, Lao, Latin, Malayalam, Myanmar, Oriya (Odia), Sinhala, Syriac, Tamil, Telugu, Thaana, Thai, Tibetan, Vietnamese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0083fef-1130-488c-9f32-479ca69cba24",
   "metadata": {},
   "source": [
    "- Specify output file  \n",
    "\n",
    "You can output into different kinds of files (html, tsv, txt, pdf). You can output into multiple different files. List the file formats you want to output in. .txt is default output format.\n",
    "\n",
    "\n",
    "\n",
    "For more parameters you can consult the [Tesseract documentation](https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48f88964-b278-45bb-bc7b-6fb582253d5c",
   "metadata": {},
   "source": [
    "### Pytesseract\n",
    "\n",
    "Pytesseract is the Python wrapper for Google’s Tesseract OCR engine. \n",
    "\n",
    "Remember to change the location of the example file (`\"ocr-corpus/1998_location.tiff\"`) to your own files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d544f31f-bee4-4b66-8416-74b3944993f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "# Opens the image\n",
    "image_of_text = Image.open(\"ocr-corpus/1998_Location.tiff\")\n",
    "\n",
    "# Converts image to string\n",
    "string_from_image = pytesseract.image_to_string(image_of_text, lang=\"eng\")\n",
    "\n",
    "# Print first 150 chars of string\n",
    "print(string_from_image[:150])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85626d8f-9c40-4512-8f0c-cbef203970bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write string to a new file\n",
    "with open(\"ocr-corpus/1988_Location.txt\", 'w') as f:\n",
    "    f.write(string_from_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eeb23a3d-18bd-46aa-a562-0dbe2d4ee9d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#List language codes for available language in Pytesseract\n",
    "print(pytesseract.get_languages(config=''))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9893e152-e3ec-4593-8079-9b87461deb6e",
   "metadata": {},
   "source": [
    "### Batch processing\n",
    "\n",
    "Loop over files in a directory and convert any .tiff files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "009aab14-e1a9-4055-bc94-983f905b75c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "def ocr_tiff_file(filepath, lang=\"eng\"):\n",
    "    text_as_image = Image.open(filepath)\n",
    "    text_as_string = pytesseract.image_to_string(text_as_image, lang=lang)\n",
    "    new_filepath = filepath.replace(\".tiff\", \".txt\")\n",
    "    with open(new_filepath, 'w') as f:\n",
    "        f.write(text_as_string)\n",
    "    print(f\"Converted {filepath} to {new_filepath}\")\n",
    "\n",
    "\n",
    "ocr_corpus = os.listdir(\"ocr-corpus\")\n",
    "for file in ocr_corpus:\n",
    "    if file.endswith(\".tiff\"):\n",
    "        ocr_tiff_file(\"ocr-corpus/\"+file)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd92a6c9-9a91-4050-8516-fdb9b4e7c0c3",
   "metadata": {},
   "source": [
    "_Acknowledgements_: This notebook is inspired by Andrew Akhlaghi's [\"OCR and Machine Translation\"](https://programminghistorian.org/en/lessons/OCR-and-Machine-Translation) and NYU's [\"Tesseract OCR Software Tutorial\"](https://guides.nyu.edu/tesseract)."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
