{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a97e7bb-70e2-460a-9d27-5b217e2635b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting most frequent words\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    lowercase_text = text.lower()\n",
    "    split_words = re.split('\\W+', lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "text = open('kafka_metamorphosis.txt', encoding=\"utf-8\").read()\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll']\n",
    "\n",
    "all_the_words = tokenize(text)\n",
    "\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "\n",
    "number_of_desired_words = 50\n",
    "\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "#with open(\"most-frequent-words-kafka.txt\", \"w\") as file_object:\n",
    "    #file_object.write(str(most_frequent_meaningful_words))\n",
    "\n",
    "#most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "029e0725-434c-44da-af71-0d62ed67cc1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Counting most frequent words, nltk stopwords\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "text = open('kafka_metamorphosis.txt', encoding=\"utf-8\").read()\n",
    "\n",
    "def tokenize(text):\n",
    "    lowercase_text = text.lower()\n",
    "    tokenized = nltk.word_tokenize(lowercase_text)\n",
    "    split_words = [word for word in tokenized if word.isalpha()]\n",
    "    return split_words\n",
    "\n",
    "all_the_words = tokenize(text)\n",
    "\n",
    "nltk_stop_words = stopwords.words(\"english\")\n",
    "\n",
    "custom_words_to_add = []\n",
    "\n",
    "stop_words = nltk_stop_words + custom_words_to_add\n",
    "\n",
    "meaningful_words = [word for word in all_the_words if word not in stop_words]\n",
    "\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "\n",
    "number_of_desired_words = 50\n",
    "\n",
    "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
    "\n",
    "#with open(\"most-frequent-words-kafka.txt\", \"w\") as file_object:\n",
    "    #file_object.write(str(most_frequent_meaningful_words))\n",
    "\n",
    "#most_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aeee8be-6223-49b8-b4a2-57c4390d5894",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(nltk_stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a815a4-f3a7-4a37-9623-b23551ed316a",
   "metadata": {},
   "source": [
    "- What further questions might we want to explore based on word counts? Are these helpful for generating further questions of hypohteses to look into? Are there any frequent words we might want to look into further?  \n",
    "- How can we refine our stopword list?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f315e12f-879e-4746-8af6-89655f0c8a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Returning frequency count for particular word interested in\n",
    "meaningful_words_tally['vermin']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ac19c7-2c11-4e45-882f-1becf94c1c68",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Least frequent words\n",
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "def tokenize(text):\n",
    "    lowercase_text = text.lower()\n",
    "    split_words = re.split('\\W+', lowercase_text)\n",
    "    return split_words\n",
    "\n",
    "text = open('kafka_metamorphosis.txt', encoding=\"utf-8\").read()\n",
    "\n",
    "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
    " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
    " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
    " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
    " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
    " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
    " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
    " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
    " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
    " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more',\n",
    " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so',\n",
    " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp']\n",
    "\n",
    "all_the_words = tokenize(text)\n",
    "\n",
    "meaningful_words = [word for word in all_the_words if word not in stopwords]\n",
    "\n",
    "meaningful_words_tally = Counter(meaningful_words)\n",
    "\n",
    "number_of_desired_words = 50\n",
    "\n",
    "least_frequent_meaningful_words = meaningful_words_tally.most_common()[:-number_of_desired_words-1:-1]\n",
    "least_frequent_meaningful_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d0d0cf7-349d-4cf5-b9e2-e0a393f4c48f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
