{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d830a488-3e88-4eb7-9942-5804f07cec9a",
   "metadata": {},
   "source": [
    "# Most Frequent Words"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e76e1ce-bfe1-4cc9-8b99-ba2bacf678cb",
   "metadata": {},
   "source": [
    "Finding most frequent words for multiple texts in a directory."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca35dc-1b41-4337-ab02-75c4f21bc897",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from collections import Counter\n",
    "\n",
    "from pathlib import Path  \n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb884275-6d8d-4dc0-aa78-415a606325a2",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Set up directory path \n",
    "#change 'kafka-corpus/' to folder name your files are in\n",
    "directory_path = 'kafka-corpus/'\n",
    "text_files = glob.glob(f'{directory_path}/*.txt')\n",
    "\n",
    "#Defines a tokenizing function\n",
    "def tokenize(text):\n",
    "    lowercase_text = text.lower()\n",
    "    split_words = re.split(r'\\W+', lowercase_text)\n",
    "    tokenized = [word for word in split_words if word.isalpha()]\n",
    "    return tokenized\n",
    "\n",
    "\n",
    "#Tokenize the files and append to all_docs list\n",
    "all_docs = []\n",
    "\n",
    "for filepath in Path(directory_path).glob(\"*.txt\"):\n",
    "    with open(filepath, 'r', encoding='utf-8') as file:\n",
    "        text = file.read()\n",
    "        tokenized_text = tokenize(text)\n",
    "        all_docs.append(tokenized_text)\n",
    "\n",
    "#Display the tokens in your first file\n",
    "all_docs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9dc9660-be7e-4dc8-b98c-29768c9e9d44",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Remove stopwords\n",
    "#Stopwords: refer to \"Preprocessing\" notebook for more details on stopwords\n",
    "\n",
    "#Load custom stopwords list (this is the default spacy list)\n",
    "#open your txt file and convert to a Python list\n",
    "with open(\"custom-stopwords.txt\", \"r\") as file_object:\n",
    "    custom_stopwords = [s.rstrip('\\n') for s in file_object.readlines()] \n",
    "\n",
    "custom_stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef5bf9d7-446c-4b8e-bded-4d2bd2b8aac0",
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Define a function to remove stopwords from tokens\n",
    "def remove_stopwords(list_of_tokens, stopwords):\n",
    "    return [token for token in list_of_tokens if token not in stopwords]\n",
    "\n",
    "all_docs_no_stop = []\n",
    "\n",
    "for file in all_docs: \n",
    "    nostop = remove_stopwords(file, custom_stopwords)\n",
    "    all_docs_no_stop.append(nostop)\n",
    "\n",
    "#Display the tokens of your first file with stopwords removed    \n",
    "all_docs_no_stop[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "758e674f-2cdf-42a4-bfa8-a9f908c7d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define a function to print out most frequent words for each file\n",
    "#This will print out the 50 most frequent words for each file\n",
    "#If you want more or less frequent words change \"number_of_top_words = \" \n",
    "#to the number you want\n",
    "def print_frequent_words(list_of_tokens):\n",
    "    for i in range(len(list_of_tokens)):\n",
    "        text_name = text_files[i]\n",
    "        words_tally = Counter(list_of_tokens[i])\n",
    "        number_of_top_words = 50\n",
    "        most_frequent_words = words_tally.most_common(number_of_top_words)\n",
    "        print(text_name, most_frequent_words, '\\n')    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8150445b-f311-4ec4-9128-9936f1fac3d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Call the function on your list of tokens\n",
    "print_frequent_words(all_docs_no_stop) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f8de667-cad7-4f20-bd18-96e02d1805e6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
