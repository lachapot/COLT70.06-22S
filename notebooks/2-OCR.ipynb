{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8dff40d1-aaf4-456f-b262-f3b70f68d6e5",
   "metadata": {},
   "source": [
    "# Optical Character Recognition (OCR) using ImageMagic and Tesseract"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0e117be-986d-4984-8629-591f84058f97",
   "metadata": {},
   "source": [
    "Creating usable digital text is the precondition to text analysis. Much of computational text analysis relies on Optical Character Recognition — on the possibility of converting scanned images to machine-encoded text. Yet OCR quality remains an issue and fundamentally impact the possibilities of analysis. \n",
    "\n",
    "> “OCR techniques still favor a very particular type of Roman-based font, which omits non-Western print traditions like Chinese woodblocks, non-print traditions like medieval manuscripts, or even regionally eclectic print traditions like German Fraktur.” (Piper, Andrew, et al. \"The Page Image: Towards a Visual History of Digital Documents.\" Book History, vol. 23, 2020, p. 365-397., p. 366)\n",
    "\n",
    "> “OCR was largely developed to process typewritten, English-language, mid-twentieth-century business documents. With that kind of input, OCR is remarkably reliable, transcribing with accuracy in the upper 90 percents. Turn an OCR engine toward historical documents, however, with distinct typography, complex layouts, torn pages, smeared ink, and any number of features those OCR engines were not trained to discern, then the reliability of OCR transcription declines precipitously.” (Cordell, Ryan. [\"Why You (A Humanist) Should Care About Optical Character Recognition\"](https://ryancordell.org/research/why-ocr/))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1fea48d0-1c5d-41fc-ae97-979c27058d15",
   "metadata": {},
   "source": [
    "## Image Preprocessing: Improve image quality with ImageMagic\n",
    "\n",
    "Tesseract requires high quality TIFF (Tagged Image File Format) images to work well. Some images will be easier to OCR than others. A good quality image will improve the accuracy of the OCR. Some images might have a lot of “noise” — distracting variations in brightness, differences in fonts and sizes, errant markings, speckled pages, skewed pages, damage to the document. Things you can do to improve image quality include: crop the picture to remove excess border space; straight the image (deskew); remove noise.\n",
    "\n",
    "We can do some preprocessing of the image to try and minimize noise and its impact on OCR quality."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80458ec3-8e0b-4bd2-a24e-54688eb028b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert pdf to tiff and improve image quality\n",
    "!convert -density 300 INPUT_FILENAME.pdf -depth 8 -strip -background white -alpha off OUTPUT_FILENAME.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9f8e515f-cca6-4cbc-8ca8-87d2df847047",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "zsh:1: command not found: convert\n"
     ]
    }
   ],
   "source": [
    "#convert pdf to tiff and improve image quality\n",
    "!convert -density 300 \"ocr-corpus/1998_Location.pdf\" -depth 8 -strip -background white -alpha off OUTPUT_FILENAME.tiff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa62675-c282-40a6-9682-8890793174ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8cf1a179-02d6-449a-aeaa-eb63383652b5",
   "metadata": {},
   "source": [
    "`density *width*`\n",
    "controls image resolution\n",
    "\n",
    "`depth *value*`\n",
    "controls depth of the image\n",
    "\n",
    "`strip`\n",
    "strips the document of any comments or any extraneous information\n",
    "\n",
    "`background *colour*`\n",
    "sets the background color\n",
    "\n",
    "`alpha *type*`\n",
    "controls the transparency of  a colour–if it is off it means that the source color will not be visible\n",
    "\n",
    "The `density` and `depth` commands both make sure the file has the appropriate dots per inch (DPI) for OCR. The `strip`, `background`, and `alpha` commands make sure that the file has the right background."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c6d2e7-582b-4d0e-bee0-2ad737546b77",
   "metadata": {},
   "source": [
    "## OCR with Tesseract\n",
    "\n",
    "Tesseract supports over 110 languages including non-western languages and writing systems. It is a free and open-source software maintained by Google. It can be a good alternative to commercial software, such as ABBYY FineReader.\n",
    "\n",
    "Now that you have converted your files into TIFF and preprocessed your images you can use Tesseract to recognize and extract the text from the image. \n",
    "\n",
    "At its simplest, OCRing with tesseract follows a simple syntax:\n",
    "`tesseract imagename outputbase`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11e9588b-3797-42bc-92db-8a11b2ea3250",
   "metadata": {},
   "source": [
    "A number of options can be added:\n",
    "- `-l *LANG*`\n",
    "\n",
    "Add `-l LANG` to the command where LANG is the three character language code from the list of supported languages.  \n",
    "\n",
    "English is used as default language. \n",
    "\n",
    "Languages in Tesseract:\n",
    "afr (Afrikaans), amh (Amharic), ara (Arabic), asm (Assamese), aze (Azerbaijani), aze_cyrl (Azerbaijani - Cyrilic), bel (Belarusian), ben (Bengali), bod (Tibetan), bos (Bosnian), bre (Breton), bul (Bulgarian), cat (Catalan; Valencian), ceb (Cebuano), ces (Czech), chi_sim (Chinese simplified), chi_tra (Chinese traditional), chr (Cherokee), cos (Corsican), cym (Welsh), dan (Danish), deu (German), div (Dhivehi), dzo (Dzongkha), ell (Greek, Modern, 1453-), eng (English), enm (English, Middle, 1100-1500), epo (Esperanto), equ (Math / equation detection module), est (Estonian), eus (Basque), fas (Persian), fao (Faroese), fil (Filipino), fin (Finnish), fra (French), frk (Frankish), frm (French, Middle, ca.1400-1600), fry (West Frisian), gla (Scottish Gaelic), gle (Irish), glg (Galician), grc (Greek, Ancient, to 1453), guj (Gujarati), hat (Haitian; Haitian Creole), heb (Hebrew), hin (Hindi), hrv (Croatian), hun (Hungarian), hye (Armenian), iku (Inuktitut), ind (Indonesian), isl (Icelandic), ita (Italian), ita_old (Italian - Old), jav (Javanese), jpn (Japanese), kan (Kannada), kat (Georgian), kat_old (Georgian - Old), kaz (Kazakh), khm (Central Khmer), kir (Kirghiz; Kyrgyz), kmr (Kurdish Kurmanji), kor (Korean), kor_vert (Korean vertical), lao (Lao), lat (Latin), lav (Latvian), lit (Lithuanian), ltz (Luxembourgish), mal (Malayalam), mar (Marathi), mkd (Macedonian), mlt (Maltese), mon (Mongolian), mri (Maori), msa (Malay), mya (Burmese), nep (Nepali), nld (Dutch; Flemish), nor (Norwegian), oci (Occitan post 1500), ori (Oriya), osd (Orientation and script detection module), pan (Panjabi; Punjabi), pol (Polish), por (Portuguese), pus (Pushto; Pashto), que (Quechua), ron (Romanian; Moldavian; Moldovan), rus (Russian), san (Sanskrit), sin (Sinhala; Sinhalese), slk (Slovak), slv (Slovenian), snd (Sindhi), spa (Spanish; Castilian), spa_old (Spanish; Castilian - Old), sqi (Albanian), srp (Serbian), srp_latn (Serbian - Latin), sun (Sundanese), swa (Swahili), swe (Swedish), syr (Syriac), tam (Tamil), tat (Tatar), tel (Telugu), tgk (Tajik), tha (Thai), tir (Tigrinya), ton (Tonga), tur (Turkish), uig (Uighur; Uyghur), ukr (Ukrainian), urd (Urdu), uzb (Uzbek), uzb_cyrl (Uzbek - Cyrilic), vie (Vietnamese), yid (Yiddish), yor (Yoruba)\n",
    "\n",
    "If the language you are using is not included but you have trained model for this language already you can pipe in the model to Tesseract and use your own model for OCR."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9314152-8923-4fd2-bc93-9791ffd16480",
   "metadata": {},
   "source": [
    "- `-l *SCRIPT*`  \n",
    "\n",
    "Specifies the script to use. \n",
    "\n",
    "Scripts in Tesseract: Arabic, Armenian, Bengali, Canadian_Aboriginal, Cherokee, Cyrillic, Devanagari, Ethiopic, Fraktur, Georgian, Greek, Gujarati, Gurmukhi, HanS (Han simplified), HanS_vert (Han simplified, vertical), HanT (Han traditional), HanT_vert (Han traditional, vertical), Hangul, Hangul_vert (Hangul vertical), Hebrew, Japanese, Japanese_vert (Japanese vertical), Kannada, Khmer, Lao, Latin, Malayalam, Myanmar, Oriya (Odia), Sinhala, Syriac, Tamil, Telugu, Thaana, Thai, Tibetan, Vietnamese."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0083fef-1130-488c-9f32-479ca69cba24",
   "metadata": {},
   "source": [
    "- Specify output file\n",
    "You can output into different kinds of files (html, tsv, txt, pdf). You can output into multiple different files. List the file formats you want to output in. Txt is default output format.\n",
    "\n",
    "\n",
    "\n",
    "For more parameters you can consult the [Tesseract documentation](https://github.com/tesseract-ocr/tesseract/blob/main/doc/tesseract.1.asc)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "321155bd-9620-4327-936e-98f6c0f3781a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tesseract testing/eurotext.tif testing/eurotext-eng -l eng txt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
